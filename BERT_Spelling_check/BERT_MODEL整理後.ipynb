{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, BertPreTrainedModel, BertConfig, BertTokenizer, BertModel\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#加入CWC語料\n",
    "#用多餘語料，然後產生標記檔 \n",
    "news = open('1209\\\\newsCorpus.txt', 'r', encoding='utf-8')\n",
    "err = open('1209\\\\對比資料庫.txt', 'r', encoding='utf-8')  \n",
    "#test_err = open('1209\\\\test_err.txt', 'w', encoding='utf-8')\n",
    "max_len = 110\n",
    "with open('1209\\\\test_database.txt', 'r', encoding='utf-8') as test:\n",
    "    test_data = []\n",
    "    while True:\n",
    "        line = test.readline()\n",
    "        if not line:break\n",
    "        test_data.append(line.replace('\\n', ''))\n",
    "test_label = []\n",
    "with open('1209\\\\train_dataset.txt', 'w', encoding='utf-8') as train_data:\n",
    "        t = {}\n",
    "        e_num = 0\n",
    "        while True: \n",
    "            err_line = err.readline()\n",
    "            if not err_line:break\n",
    "            lineTo = err_line.split(',')\n",
    "            if len(lineTo[1].replace(' ',''))<=3 and len(lineTo[0].replace(' ',''))<=3:continue\n",
    "            if ('＆' in lineTo[1]) or ('&' in lineTo[1]) or ('+' in lineTo[1])  or ('＄' in lineTo[1]) or ('$' in lineTo[1]):continue\n",
    "            if len(lineTo[0].replace(' ',''))>60:continue\n",
    "            if len(lineTo)>0 :        \n",
    "                if len(lineTo[9])==3 and lineTo[9]=='ADT':\n",
    "                    if lineTo[9] in t.keys():t[lineTo[9]] += 1\n",
    "                    else:\n",
    "                        err_sen = lineTo[1].replace(' ','')\n",
    "                        if err_sen.find(lineTo[11].replace(' ','')) < 0 or err_sen.count(lineTo[11].replace(' ',''))>1:continue\n",
    "                        if len(lineTo[11])>1:\n",
    "                            start, end = err_sen.find(lineTo[11][0]), err_sen.find(lineTo[11][0])+len(lineTo[11])-1\n",
    "                            #print(start, end)\n",
    "                        else:\n",
    "                            start, end = err_sen.find(lineTo[11]), err_sen.find(lineTo[11])\n",
    "                        e_num += 1\n",
    "                        \n",
    "                        labels = ''\n",
    "                        for i in range(len(lineTo[1].replace(' ',''))):\n",
    "                            if i >= start and i <= end:labels += '1'\n",
    "                            else:labels += '0'\n",
    "                        for i in range(max_len-len(lineTo[1].replace(' ',''))):\n",
    "                            labels += '0'\n",
    "                        '''\n",
    "                        if lineTo[1].replace(' ','') in test_data:\n",
    "                            test_label.append([lineTo[1].replace(' ',''), labels])\n",
    "                            continue\n",
    "                        if lineTo[1].replace(' ','') in test_data:\n",
    "                            test_err.write(lineTo[1].replace(' ','')+','+labels+'\\n')\n",
    "                            continue\n",
    "                        '''\n",
    "                        #train_data.write(lineTo[0].replace(' ','')+','+lineTo[1].replace(' ','')+','+labels+'\\n')#寫修正句&偏誤句\n",
    "                        train_data.write(lineTo[1].replace(' ','')+','+labels+'\\n')#寫偏誤句\n",
    "        '''\n",
    "        tmp = [i[0] for i in test_label]\n",
    "        for i in test_data:\n",
    "            if i not in tmp:\n",
    "                labels = ''\n",
    "                for _ in range(80):labels += '0'\n",
    "                test_err.write(i+','+labels+'\\n')\n",
    "        for i in test_label:\n",
    "            test_err.write(i[0]+','+i[1]+'\\n')\n",
    "        '''\n",
    "        n_num = 0\n",
    "        \n",
    "        while True:\n",
    "            labels = ''\n",
    "            news_line = news.readline()\n",
    "            if not news_line:break\n",
    "            if n_num >= 7263:break\n",
    "            for _ in range(max_len):labels += '0'\n",
    "            train_data.write(news_line.replace('\\n','') + ',' + labels + '\\n')#寫新聞句            \n",
    "            n_num += 1            \n",
    "        news.close()\n",
    "        \n",
    "        \n",
    "        err.close()\n",
    "        print(t, e_num, n_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OMS': 11523, 'MOD': 1995, 'MST': 11261, 'ADT': 8745, '009': 1} 11261 11261\n"
     ]
    }
   ],
   "source": [
    "#加入CWC語料\n",
    "#用誤代語料，然後產生標記檔 \n",
    "news = open('1209\\\\newsCorpus.txt', 'r', encoding='utf-8')\n",
    "err = open('1209\\\\對比資料庫.txt', 'r', encoding='utf-8')  \n",
    "#test_err = open('1209\\\\test_err.txt', 'w', encoding='utf-8')\n",
    "max_len = 110\n",
    "err_type = []\n",
    "        \n",
    "test_label = []\n",
    "with open('1209\\\\train_dataset.txt', 'w', encoding='utf-8') as train_data:\n",
    "        t = {}\n",
    "        e_num = 0\n",
    "        while True: \n",
    "            err_line = err.readline()\n",
    "            if not err_line:break\n",
    "            lineTo = err_line.split(',')\n",
    "            err_sen = lineTo[1].replace(' ','')\n",
    "            if len(lineTo[1].replace(' ',''))<=3 and len(lineTo[0].replace(' ',''))<=3:continue\n",
    "            #if err_sen.find(lineTo[11].replace(' ','')) < 0 or err_sen.count(lineTo[11].replace(' ',''))>1:continue\n",
    "            if ('＆' in lineTo[1]) or ('&' in lineTo[1]) or ('+' in lineTo[1])  or ('＄' in lineTo[1]) or ('$' in lineTo[1]):continue\n",
    "            if len(lineTo[0].replace(' ',''))>110:continue\n",
    "            if len(lineTo)>0 : \n",
    "                if len(lineTo[9])==3:\n",
    "                    if lineTo[9] in t.keys():t[lineTo[9]] += 1\n",
    "                    else:t[lineTo[9]] = 1\n",
    "                        \n",
    "                if len(lineTo[9])==3:\n",
    "                    if lineTo[9]=='MST':\n",
    "                        err_sen = lineTo[1].split()\n",
    "                        cor_sen = lineTo[0].split()\n",
    "                        #print(err_sen, cor_sen)                        \n",
    "                        \n",
    "                        labels = ''\n",
    "                        for i in range(len(err_sen)):\n",
    "                            if cor_sen[i] != err_sen[i]:labels += '1'*len(err_sen[i])\n",
    "                            else:labels += '0'*len(err_sen[i])\n",
    "                        for i in range(max_len-len(lineTo[1].replace(' ',''))):\n",
    "                            labels += '0'\n",
    "                        \n",
    "                        #train_data.write(lineTo[0].replace(' ','')+','+lineTo[1].replace(' ','')+','+labels+'\\n')#寫修正句&偏誤句\n",
    "                        train_data.write(lineTo[1].replace(' ','')+','+labels+','+lineTo[0].replace(' ','')+'\\n')#寫誤代句\n",
    "                        e_num += 1\n",
    "        \n",
    "        n_num = 0\n",
    "        \n",
    "        while True:\n",
    "            labels = ''\n",
    "            news_line = news.readline()\n",
    "            if n_num >= 11261:break\n",
    "            if not news_line:break\n",
    "            for _ in range(max_len):labels += '0'\n",
    "            train_data.write(news_line.replace('\\n','') + ',' + labels + '\\n')#寫新聞句            \n",
    "            n_num += 1 \n",
    "            \n",
    "news.close()\n",
    "err.close()\n",
    "print(t, e_num, n_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 0\n"
     ]
    }
   ],
   "source": [
    "e_num = 0\n",
    "n_num = 0\n",
    "confusion = open(\"1209\\\\字音混淆集.txt\",'r',encoding='utf-8') #經過字形與字音相似度計算後，為相似字的表\n",
    "\n",
    "dict={}\n",
    "while(True):\n",
    "    line = confusion.readline().strip()\n",
    "    \n",
    "    if line:\n",
    "        line = line.split('　')\n",
    "        if len(line)!=1:\n",
    "            dict[line[0]] = line[1]\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "confusion.close()\n",
    "\n",
    "table = open(\"1209\\\\wordtest4.txt\",'r',encoding='utf-8') #要挑的字表\n",
    "s=0\n",
    "dict2={}\n",
    "\n",
    "while(True):\n",
    "    line = table.readline().strip()\n",
    "    \n",
    "    if not line:break\n",
    "    line = line.split(',')\n",
    "    dict2[s] = line[0]\n",
    "    s+=1\n",
    "        \n",
    "table.close()\n",
    "\n",
    "import random\n",
    "max_len = 110\n",
    "def test_(c): #產生錯字\n",
    "    if random.random() <= 0.8: #有0.8的機率是相似的錯字\n",
    "        line = dict[c].split(' ')\n",
    "        return line[random.randint(0,len(line)-1)]\n",
    "    else:    #有0.2的機率是隨機抽字\n",
    "        a = random.randint(0,len(dict2)-1)\n",
    "        while(c==dict2[a]):\n",
    "            a = random.randint(0,len(dict2)-1)\n",
    "        return dict2[a]\n",
    "\n",
    "file =  open(\"1209\\\\newsCorpus.txt\",'r',encoding='utf-8') #要被變成訓練資料的句子，也是校正層解答\n",
    "answer_list=''\n",
    "a=0\n",
    "file2 =  open(\"1209\\\\train_dataset.txt\",'w',encoding='utf-8') #產生的訓練資料句\n",
    "\n",
    "while True:\n",
    "    \n",
    "    line2=''\n",
    "    answer=[]\n",
    "    line = file.readline()\n",
    "    if not line:break\n",
    "    if e_num >= 200000: break\n",
    "    for ch in ['， ', ', ', ' ,', ',']:#\n",
    "        line = line.replace(ch, '，')\n",
    "    line = line.replace('︵', '(')\n",
    "    line = line.replace('︶', ')')\n",
    "    line = line.replace(':', '：')\n",
    "    if len(line)>max_len:continue\n",
    "    e_num += 1\n",
    "    for i in line.replace('\\n', ''):\n",
    "        if a==0:\n",
    "            if random.randint(1,15) == 10: #有1/15的機率 把這個字當成錯字\n",
    "                a+=1\n",
    "                if dict.get(i) != None: #若這個字不再字表中，則選擇下一個字為錯字 會有a去計數\n",
    "                    line2+=test_(i)\n",
    "                    a-=1\n",
    "                    answer.append(1)\n",
    "                else:\n",
    "                    line2+=i\n",
    "                    answer.append(0)\n",
    "            else:\n",
    "                line2+=i\n",
    "                answer.append(0)\n",
    "                \n",
    "        else:   #若a>0以上，則要一直挑錯字，直到a==0\n",
    "            if dict.get(i) != None: #\n",
    "                line2+=test_(i)\n",
    "                a-=1\n",
    "                answer.append(1)\n",
    "            else:\n",
    "                line2+=i\n",
    "                answer.append(0)\n",
    "                \n",
    "    for j in answer:  #寫入答案\n",
    "        answer_list+=str(j)\n",
    "    for i in range(max_len-len(answer_list)):answer_list += '0'\n",
    "    file2.write(line2 + ',' + answer_list + '\\n')\n",
    "    answer_list=''\n",
    "'''\n",
    "news = open('1209\\\\newsCorpus.txt', 'r', encoding='utf-8')\n",
    "n_num = 0\n",
    "while True:\n",
    "    labels = ''\n",
    "    news_line = news.readline()\n",
    "    if not news_line:break\n",
    "    if n_num >= 1e5:break\n",
    "    for _ in range(max_len):labels += '0'\n",
    "    file2.write(news_line.replace('\\n','') + ',' + labels + '\\n')#寫新聞句 \n",
    "    n_num += 1\n",
    "    \n",
    "news.close()\n",
    "'''\n",
    "file2.close()  \n",
    "file.close()\n",
    "print(e_num, n_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 0\n"
     ]
    }
   ],
   "source": [
    "def write_Wrong_word():\n",
    "    MAX_LEN = 110\n",
    "    e_num = 0\n",
    "    n_num = 0\n",
    "    confusion = open(\"1209\\\\字音混淆集.txt\",'r',encoding='utf-8') #經過字形與字音相似度計算後，為相似字的表\n",
    "\n",
    "    dict={}\n",
    "    while(True):\n",
    "        line = confusion.readline().strip()\n",
    "        \n",
    "        if not line:break\n",
    "        line = line.split('　')\n",
    "        if len(line)!=1:dict[line[0]] = line[1]\n",
    "          \n",
    "    confusion.close()\n",
    "\n",
    "    table = open(\"1209\\\\wordtest4.txt\",'r',encoding='utf-8') #要挑的字表\n",
    "    s=0\n",
    "    dict2={}\n",
    "\n",
    "    while(True):\n",
    "        line = table.readline().strip()\n",
    "        \n",
    "        if not line:break\n",
    "        line = line.split(',')\n",
    "        dict2[s] = line[0]\n",
    "        s+=1\n",
    "            \n",
    "    table.close()\n",
    "\n",
    "    import random\n",
    "    def test_(c, prob): #產生錯字\n",
    "        prob /= 0.15\n",
    "        if prob < 0.8:\n",
    "        #if np.random.choice([True, False], p=[0.8, 0.2]): #有0.8的機率是相似的錯字\n",
    "            line = dict[c].split(' ')\n",
    "            return line[random.randint(0,len(line)-1)]\n",
    "        else:    #有0.2的機率是隨機抽字\n",
    "            a = random.randint(0,len(dict2)-1)\n",
    "            while(c==dict2[a]):\n",
    "                a = random.randint(0,len(dict2)-1)\n",
    "            return dict2[a]\n",
    "    \n",
    "    file = open(\"1209\\\\newsCorpus.txt\",'r',encoding='utf-8') #要被變成訓練資料的句子，也是校正層解答\n",
    "    answer_list=''\n",
    "    a=0\n",
    "    file2 = open(\"1209\\\\train_dataset.txt\",'w',encoding='utf-8') #產生的訓練資料句\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        line2=''\n",
    "        answer=[]\n",
    "        line = file.readline()\n",
    "        if not line:break\n",
    "        if e_num >= 2e4:\n",
    "            '''\n",
    "            n_num = 0\n",
    "            while True:\n",
    "                \n",
    "                labels = ''\n",
    "                news_line = file.readline()\n",
    "                if not news_line:break\n",
    "                if n_num >= 2e4:break\n",
    "                for _ in range(MAX_LEN):labels += '0'\n",
    "                file2.write(news_line.replace('\\n','') + ',' + labels + '\\n')#寫新聞句 \n",
    "                n_num += 1\n",
    "            '''\n",
    "            break\n",
    "        for ch in ['， ', ', ', ' ,', ',']:#\n",
    "            line = line.replace(ch, '，')\n",
    "        line = line.replace('︵', '(')\n",
    "        line = line.replace('︶', ')')\n",
    "        line = line.replace(':', '：')\n",
    "        if len(line)>MAX_LEN:continue\n",
    "        e_num += 1\n",
    "        for i in line.replace('\\n', ''):\n",
    "            if a==0:\n",
    "                prob = random.random()\n",
    "                if prob<=0.15:#有1/15的機率 把這個字當成錯字\n",
    "                #if np.random.choice([True, False], p=[0.15, 0.85]): \n",
    "                    a+=1\n",
    "                    if dict.get(i) != None: #若這個字不再字表中，則選擇下一個字為錯字 會有a去計數\n",
    "                        line2+=test_(i, prob)\n",
    "                        a-=1\n",
    "                        answer.append(1)\n",
    "                    else:\n",
    "                        line2+=i\n",
    "                        answer.append(0)\n",
    "                else:\n",
    "                    line2+=i\n",
    "                    answer.append(0)\n",
    "                    \n",
    "            else:   #若a>0以上，則要一直挑錯字，直到a==0\n",
    "                if dict.get(i) != None: #\n",
    "                    line2+=test_(i, prob)\n",
    "                    a-=1\n",
    "                    answer.append(1)\n",
    "                else:\n",
    "                    line2+=i\n",
    "                    answer.append(0)\n",
    "                    \n",
    "        for j in answer:  #寫入答案\n",
    "            answer_list+=str(j)\n",
    "        for i in range(MAX_LEN-len(answer_list)):answer_list += '0'\n",
    "        file2.write(line2 + ',' + answer_list + '\\n')\n",
    "        file2.write(line.replace('\\n', '') + ',' + ''.join([str(0) for i in range(MAX_LEN)]) + '\\n')\n",
    "        answer_list=''\n",
    "    file2.close()  \n",
    "    file.close()\n",
    "    print(e_num, n_num)\n",
    "    \n",
    "write_Wrong_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['例如煤炭堆積待運量佔年產量的三成之多，致使四億噸煤無法自產地運出，每年減少出口的煤炭達六百萬到一千萬噸，出口損失兩億到三億五千萬元。', '基隆釋警鞠表示，忠東戰爭爆發，渭確寶斜內外僑安全與社會治氨，井方已奉命全面加強執行外極勞工專案，呼籲廠商步要殷外籍勞工工價較菸，而予以僱拐，滋濕治安問題。'] ['結果春耕一延再延，大批稻作無法插秧，更嚴重的是，許多旱栽作物，如華南山區的高地稻米，也因雨量太少不能播種。', '花蓮縣務會議，今天上午在花蓮縣政府召開，由花蓮縣長吳國棟主持。'] [0, 1] [0, 0] 79940 60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = [], []\n",
    "with open('1209\\\\train_dataset.txt', 'r', encoding='utf-8') as train_data:\n",
    "    while True:\n",
    "        line = train_data.readline()\n",
    "        if not line:break\n",
    "        line = line.replace('\\n', '')\n",
    "        data = line.split(',')\n",
    "        x.append(data[0])\n",
    "        y.append(1 if '1' in data[1] else 0)\n",
    "        #y.append([int(i) for i in data[1]])\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val =\\\n",
    "    train_test_split(x, y, test_size=0.00075, random_state=2021)\n",
    "print(x_train[:2], x_val[:2], y_train[:2], y_val[:2], len(x_train), len(x_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 110\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "def preprocessing_for_bert(data):\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=False,\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert_At(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\islab\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers-4.1.1-py3.8.egg\\transformers\\tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  891, 1963, 4209, 4151, 1831, 4948, 2521, 6880, 7030,  861, 2399,\n",
      "         4496, 7030, 4638,  676, 2768,  722, 1914, 8024, 5636,  886, 1724, 1023,\n",
      "         1697, 4209, 4192, 3791, 5632, 4496, 1765, 6880, 1139, 8024, 3680, 2399,\n",
      "         3938, 2208, 1139, 1366, 4638, 4209, 4151, 6888, 1063, 4636, 5857, 1168,\n",
      "          671, 1283, 5857, 1697, 8024, 1139, 1366, 3010, 1927, 1060, 1023, 1168,\n",
      "          676, 1023,  758, 1283, 5857, 1039,  511,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0],\n",
      "        [ 101, 1825, 7384, 7026, 6356, 7495, 6134, 4850, 8024, 2566, 3346, 2782,\n",
      "         4261, 4255, 4634, 8024, 3948, 4825, 2188, 3162, 1058, 1912, 1009, 2128,\n",
      "         1059, 5645, 4852, 3298, 3780, 3710, 8024,  759, 3175, 2347, 1938, 1462,\n",
      "         1059, 7481, 1217, 2485, 1822, 6121, 1912, 3513, 1246, 2339, 2201, 3428,\n",
      "         8024, 1461, 5100, 2449, 1555, 3635, 6206, 3668, 1912, 5093, 1246, 2339,\n",
      "         2339, 1019, 6733, 5839, 8024, 5445,  750,  809, 1017, 2866, 8024, 3996,\n",
      "         4086, 3780, 2128, 1558, 7539,  511,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]])\n"
     ]
    }
   ],
   "source": [
    "#train_inputs = preprocessing_for_bert(x_train)\n",
    "#val_inputs = preprocessing_for_bert(x_val)\n",
    "\n",
    "train_inputs, train_masks = preprocessing_for_bert_At(x_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert_At(x_val)\n",
    "print(train_inputs[:2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 64\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "train_data[:1], tokenizer.decode(train_data[:1][0][0]), val_data[:1], tokenizer.decode(val_data[:1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 101,  891, 1963, 4209, 4151, 1831, 4948, 2521, 6880, 7030,  861, 2399,\n",
       "           4496, 7030, 4638,  676, 2768,  722, 1914, 8024, 5636,  886, 1724, 1023,\n",
       "           1697, 4209, 4192, 3791, 5632, 4496, 1765, 6880, 1139, 8024, 3680, 2399,\n",
       "           3938, 2208, 1139, 1366, 4638, 4209, 4151, 6888, 1063, 4636, 5857, 1168,\n",
       "            671, 1283, 5857, 1697, 8024, 1139, 1366, 3010, 1927, 1060, 1023, 1168,\n",
       "            676, 1023,  758, 1283, 5857, 1039,  511,  102,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0],\n",
       "          [ 101, 1825, 7384, 7026, 6356, 7495, 6134, 4850, 8024, 2566, 3346, 2782,\n",
       "           4261, 4255, 4634, 8024, 3948, 4825, 2188, 3162, 1058, 1912, 1009, 2128,\n",
       "           1059, 5645, 4852, 3298, 3780, 3710, 8024,  759, 3175, 2347, 1938, 1462,\n",
       "           1059, 7481, 1217, 2485, 1822, 6121, 1912, 3513, 1246, 2339, 2201, 3428,\n",
       "           8024, 1461, 5100, 2449, 1555, 3635, 6206, 3668, 1912, 5093, 1246, 2339,\n",
       "           2339, 1019, 6733, 5839, 8024, 5445,  750,  809, 1017, 2866, 8024, 3996,\n",
       "           4086, 3780, 2128, 1558, 7539,  511,  102,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0],\n",
       "          [ 101, 5390, 6716, 3176, 3312, 3560, 6542, 4958, 3149, 5739, 7027, 5993,\n",
       "           8024, 7093, 5543, 1146, 6795, 4156, 2492, 4255, 4634, 4638, 2485, 1045,\n",
       "           8024, 2344, 1282,  753, 4638, 3582, 1519, 2175, 6221,  679, 1168, 1765,\n",
       "           7481, 2792, 1358, 4638, 5026, 2154,  511,  102,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0]]),\n",
       "  tensor([0, 1, 1]),\n",
       "  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])),\n",
       " '[CLS] 例 如 煤 炭 堆 積 待 運 量 佔 年 產 量 的 三 成 之 多 ， 致 使 四 億 噸 煤 無 法 自 產 地 運 出 ， 每 年 減 少 出 口 的 煤 炭 達 六 百 萬 到 一 千 萬 噸 ， 出 口 損 失 兩 億 到 三 億 五 千 萬 元 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " (tensor([[ 101, 5178, 3362, 3217, 5449,  671, 2454, 1086, 2454, 8024, 1920, 2821,\n",
       "           4940,  868, 4192, 3791, 2991, 4913, 8024, 3291, 1713, 7028, 4638, 3221,\n",
       "           8024, 6258, 1914, 3197, 3420,  868, 4289, 8024, 1963, 5836, 1298, 2255,\n",
       "           1281, 4638, 7770, 1765, 4940, 5101, 8024,  738, 1728, 7433, 7030, 1922,\n",
       "           2208,  679, 5543, 3064, 4934,  511,  102,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0],\n",
       "          [ 101, 5709, 5909, 5238, 1243, 3298, 6359, 8024,  791, 1921,  677, 1286,\n",
       "           1762, 5709, 5909, 5238, 3124, 2424, 1374, 7274, 8024, 4507, 5709, 5909,\n",
       "           5238, 7269, 1425, 1751, 3477,  712, 2898,  511,  102,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0],\n",
       "          [ 101, 1071,  800, 7521, 3309, 3951, 5543, 1159, 4412, 4638,  782,  752,\n",
       "           6365, 1240, 8024, 6187, 2886, 6141, 4113,  941, 1399, 1199, 5244, 7805,\n",
       "            673, 1282, 1724, 3641, 4638, 4982,  898, 3360, 5645,  673, 1282, 3641,\n",
       "           4638, 3458, 2119, 6340, 8024,  688, 7271, 2200, 1728, 7770, 7972, 6041,\n",
       "            828,  511,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0]]),\n",
       "  tensor([0, 0, 1]),\n",
       "  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])),\n",
       " '[CLS] 結 果 春 耕 一 延 再 延 ， 大 批 稻 作 無 法 插 秧 ， 更 嚴 重 的 是 ， 許 多 旱 栽 作 物 ， 如 華 南 山 區 的 高 地 稻 米 ， 也 因 雨 量 太 少 不 能 播 種 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 64\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_labels, train_masks)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_labels, val_masks)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "train_data[:3], tokenizer.decode(train_data[:1][0][0]), val_data[:3], tokenizer.decode(val_data[:1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSeqClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, freeze_bert=False):\n",
    "        super(BertSeqClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, labels, attention_mask):\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "    \n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, num_labels, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        self.num_labels = num_labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "        self.rnn = nn.LSTM(bidirectional=True, num_layers=2, input_size=D_in, hidden_size=H//2, batch_first=True)  #[128, 74, 768]\n",
    "        self.output = nn.Linear(H, num_labels)\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, labels):\n",
    "        #define loss function\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids)\n",
    "        #print(outputs)\n",
    "        outputs, _ = self.rnn(outputs[0])\n",
    "        #print(outputs.size())\n",
    "        logits = self.output(outputs) \n",
    "        #print(logits, labels)\n",
    "        loss = loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.tensor([[[np.random.rand()]*2]*110], requires_grad=True)\n",
    "target = torch.tensor([[np.random.randint(0,1)]*110])\n",
    "print(input.view(-1, 2).size(), target.view(-1).size())\n",
    "output = loss(input.view(-1, 2), target.view(-1))\n",
    "output.backward()\n",
    "#print(input[0], '\\n', target[0])\n",
    "output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NUM_LABELS = 2\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "#model = BertClassifier(PRETRAINED_MODEL_NAME, NUM_LABELS)\n",
    "#model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "#model = BertForTokenClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "#model = model.to(device)\n",
    "for step, batch in enumerate(train_dataloader): #訓練資料\n",
    "    b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "    print(b_input_ids.size(), b_labels.size())\n",
    "    #out = model(input_ids=b_input_ids, labels=b_labels)\n",
    "    #print(out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    \n",
    "    #model = BertForTokenClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "    #model = BertClassifier(PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "    model = BertSeqClassifier(PRETRAINED_MODEL_NAME)\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def train(model, train_dataloader, epochs=4):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_labels, b_attn_mask = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits.view(-1, 2), b_labels.view(-1))\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        print('[epoch %d] loss: %.3f' % (epoch_i + 1, total_loss))\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "NUM_LABELS = 2\n",
    "epochs = 20\n",
    "set_seed(42) \n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs)\n",
    "losses = train(bert_classifier, train_dataloader, epochs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valIter = iter(val_dataloader)\n",
    "data = next(valIter)\n",
    "ids = data[0].to(device)\n",
    "label = data[1].to(device)\n",
    "mask = data[2].to(device)\n",
    "model.eval()\n",
    "output = model(input_ids=ids, labels=label)#, labels=label)\n",
    "print(output)\n",
    "output[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                            | 1/20 [13:06<4:09:04, 786.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 57.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                        | 2/20 [26:20<3:56:38, 788.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] loss: 23.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████                                                                    | 3/20 [39:32<3:43:46, 789.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] loss: 14.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████                                                                | 4/20 [52:44<3:30:45, 790.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 10.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████▌                                                          | 5/20 [1:05:55<3:17:39, 790.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 10.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▍                                                      | 6/20 [1:19:06<3:04:30, 790.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 8.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████████████████▎                                                  | 7/20 [1:32:17<2:51:20, 790.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 6.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▏                                              | 8/20 [1:45:29<2:38:11, 790.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 5.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████                                           | 9/20 [1:58:40<2:25:00, 790.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 6.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████▌                                      | 10/20 [2:11:50<2:11:49, 790.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 4.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████████████████████████▎                                  | 11/20 [2:25:01<1:58:38, 790.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] loss: 4.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▏                              | 12/20 [2:38:12<1:45:27, 790.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] loss: 3.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████████████████████████████                           | 13/20 [2:51:23<1:32:15, 790.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] loss: 3.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████▉                       | 14/20 [3:04:32<1:19:02, 790.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14] loss: 3.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████▊                   | 15/20 [3:17:43<1:05:52, 790.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] loss: 3.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▏               | 16/20 [3:30:54<52:42, 790.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] loss: 1.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▏           | 17/20 [3:44:03<39:30, 790.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17] loss: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████        | 18/20 [3:57:03<26:14, 787.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] loss: 0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████    | 19/20 [4:09:52<13:01, 781.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] loss: 0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 20/20 [4:22:49<00:00, 788.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] loss: 0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_dataloader, val_dataloader, epochs=4):\n",
    "    Loss = []    \n",
    "    model.train() #訓練模式\n",
    "    for i in tqdm(range(epochs)):  \n",
    "        model.train() #訓練模式\n",
    "        batch_counts = 0\n",
    "        running_loss = 0.0\n",
    "        for step, batch in enumerate(train_dataloader): #訓練資料\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_labels, b_masks = tuple(t.to(device) for t in batch)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(input_ids=b_input_ids, labels=b_labels, attention_mask=b_masks)\n",
    "            loss = out[0]\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "        torch.save(model.state_dict(), 'ckpt/bert_seq_error_cor_same_half2W_weight_'+str(i+1)+'.h5')\n",
    "        Loss.append(running_loss)\n",
    "        val_loss, val_acc = evaluate(model, val_dataloader)\n",
    "        print('[epoch %d] train_loss: %.3f val_loss: %.3f val_acc: %.3f' % (i + 1, running_loss, val_loss, val_acc))\n",
    "    return Loss\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "NUM_LABELS = 2\n",
    "epochs = 20\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs)\n",
    "losses = train(bert_classifier, train_dataloader, val_dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.272134136990644, 23.731054754549405, 14.010025119845523, 10.242651909535198, 10.041859910175845, 8.539342644355202, 6.608067794844828, 5.36839998159121, 6.968256751606532, 4.351226615741325, 4.29094233194337, 3.3915825955336913, 3.528080198695534, 3.7888826420748956, 3.109523358551087, 1.6513890810747398, 0.9680189694954606, 0.6829484997815598, 0.44084791727254924, 0.4881493357788713]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "print(losses)\n",
    "x = np.arange(1, len(losses)+1)\n",
    "y = losses\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('LOSS')  \n",
    "plt.xticks(x)\n",
    "plt.plot(x, y)\n",
    "plt.savefig('test/BertSeqTransloss{}.jpg'.format(epochs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "mode = \"sentence1times_eWord\"\n",
    "\n",
    "def get_test_result(dataloader):\n",
    "    y_real_s = []\n",
    "    y_pred_s = []\n",
    "    cor_count = 0\n",
    "    \n",
    "    data = {\n",
    "    \"真實標記\":[],\n",
    "    \"預測標記\":[]\n",
    "    }\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels, b_masks = tuple(t.to(device) for t in batch)    \n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = bert_classifier(input_ids = b_input_ids, labels = b_labels, attention_mask=b_masks)    \n",
    "        # Compute loss\n",
    "        loss = logits[0]\n",
    "\n",
    "        # Get the predictions    \n",
    "        pred = torch.max(logits[1], 1)[1].data\n",
    "        y_pred_s += list(pred.cpu().numpy())          \n",
    "        y_real_s += list(b_labels.cpu().numpy())\n",
    "\n",
    "        #sentence = tokenizer.decode(b_input_ids)\n",
    "    #df = pd.DataFrame(data)\n",
    "    return  y_real_s, y_pred_s\n",
    "\n",
    "# Compute the average accuracy and loss over the validation set.\n",
    "\n",
    "#y_real_s, y_pred_s = get_test_result(val_dataloader)\n",
    "\n",
    "#df.to_csv('test/Bert{}EpochErr_{}.csv'.format(epochs,mode))\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_result(dataloader):\n",
    "    y_real_s = []\n",
    "    y_pred_s = []\n",
    "    cor_count = 0\n",
    "    \n",
    "    data = {\n",
    "    \"真實標記\":[],\n",
    "    \"預測標記\":[]\n",
    "    }\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels, b_mask = tuple(t.to(device) for t in batch)    \n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = bert_classifier(input_ids = b_input_ids, labels = b_labels)    \n",
    "        # Compute loss\n",
    "        loss = logits[0]\n",
    "\n",
    "        # Get the predictions    \n",
    "\n",
    "        for logit, real, b_input_id in zip(logits[1], b_labels, b_input_ids):\n",
    "            token = [int(i) for i in b_input_id.cpu().numpy() if i != 0] \n",
    "            pred = torch.max(logit, 1)[1].data\n",
    "            sentence = tokenizer.decode(b_input_id[:len(token)]) #轉成中文句\n",
    "            realList = sentence.split()\n",
    "            predList = sentence.split()\n",
    "            predLabel = torch.nonzero(pred)\n",
    "            realLabel = torch.nonzero(real)\n",
    "\n",
    "            if realLabel.size()[0] != 0:\n",
    "                if realLabel[0].cpu().numpy() >= len(realList):continue\n",
    "                if realLabel[-1].cpu().numpy() >= len(realList):continue\n",
    "\n",
    "            if predLabel.size()[0] != 0:\n",
    "                if predLabel[0].cpu().numpy() >= len(predList):continue\n",
    "                if predLabel[-1].cpu().numpy() >= len(predList):continue  \n",
    "\n",
    "            if predLabel.size()[0] == 1:            \n",
    "                predList[predLabel[0]] = '['+predList[predLabel[0]]+']'\n",
    "            elif predLabel.size()[0] > 1:\n",
    "                for i in predLabel:\n",
    "                    predList[i[0]] = '['+predList[i[0]]+']'\n",
    "            data[\"預測標記\"].append(''.join(predList)) \n",
    "\n",
    "            if realLabel.size()[0] == 1:            \n",
    "                realList[realLabel[0][0]] = '['+realList[realLabel[0][0]]+']'\n",
    "            elif realLabel.size()[0] > 1:\n",
    "                for i in realLabel:\n",
    "                    realList[i[0]] = '['+realList[i[0]]+']'\n",
    "            data[\"真實標記\"].append(''.join(realList))\n",
    "\n",
    "            corr = torch.zeros((1,max_len)).type(torch.int64)\n",
    "            corr = corr.to(device)\n",
    "\n",
    "            if torch.equal(real, corr[0]):y_real_s += [1]\n",
    "            else:y_real_s += [0]\n",
    "\n",
    "            if torch.equal(pred, corr[0]):y_pred_s += [1] \n",
    "            elif torch.equal(pred, real):\n",
    "                y_pred_s += [0]\n",
    "                cor_count += 1\n",
    "            else:\n",
    "                y_pred_s += [0]\n",
    "\n",
    "        #sentence = tokenizer.decode(b_input_ids)\n",
    "    df = pd.DataFrame(data)\n",
    "    return cor_count, df, y_real_s, y_pred_s\n",
    "\n",
    "# Compute the average accuracy and loss over the validation set.\n",
    "\n",
    "cor_count, df, y_real_s, y_pred_s = get_test_result(val_dataloader)\n",
    "print(cor_count)\n",
    "df.to_csv('test/Bert{}EpochErr_{}.csv'.format(epochs,mode))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertSeqClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "bert_classifier = BertSeqClassifier(PRETRAINED_MODEL_NAME)\n",
    "# Tell PyTorch to run the model on GPU\n",
    "bert_classifier = bert_classifier.to(device)\n",
    "\n",
    "checkpoint = torch.load('ckpt/bert_seq_only_err4W_weight_20.h5')\n",
    "bert_classifier.load_state_dict(checkpoint)\n",
    "bert_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def show_confusion(y_real_s, y_pred_s):\n",
    "    confmat_s = confusion_matrix(y_true=y_real_s, y_pred=y_pred_s)\n",
    "    fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "    ax.matshow(confmat_s, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(confmat_s.shape[0]):\n",
    "        for j in range(confmat_s.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat_s[i,j], va='center', ha='center')\n",
    "    \n",
    "    cm_s = {'tp': confmat_s[1, 1], 'fn': confmat_s[1, 0], 'fp': confmat_s[0, 1], 'tn': confmat_s[0, 0]}\n",
    "    total = sum(cm_s.values())\n",
    "    print('--------------Detection level--------------')\n",
    "    print(\"accuracy:\", (cm_s['tp']+cm_s['tn'])/total)\n",
    "\n",
    "    recall = (cm_s['tp'])/(cm_s['tp']+cm_s['fn'])\n",
    "    print(\"recall:\", recall)\n",
    "\n",
    "    precision = (cm_s['tp'])/(cm_s['tp']+cm_s['fp'])\n",
    "    print(\"precision:\", precision)\n",
    "\n",
    "    print(\"f1-score:\", 2/((1/precision)+(1/recall)))\n",
    "\n",
    "    fa_rate = (cm_s['fp'])/(cm_s['tn']+cm_s['fp'])\n",
    "    print(\"FA-Rate:\", fa_rate)\n",
    "    plt.xlabel('Prediction')        \n",
    "    plt.ylabel('Real Label')\n",
    "    plt.show()\n",
    "    \n",
    "#show_confusion(y_real_s, y_pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([699]) torch.Size([699, 110])\n",
      "--------------Detection level--------------\n",
      "accuracy: 0.4492131616595136\n",
      "recall: 0.9769736842105263\n",
      "precision: 0.44\n",
      "f1-score: 0.6067415730337078\n",
      "FA-Rate: 0.9569620253164557\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 64\n",
    "labels, texts = [], []\n",
    "with open(\"1209\\\\中央社已處理\\\\test_answer_13.txt\",'r',encoding='utf-8') as label:\n",
    "    while True:\n",
    "        line = label.readline().strip()\n",
    "        if not line:break\n",
    "        labels.append(1 if '1' in line else 0)\n",
    "        #labels.append([int(i) for i in line]+[0 for j in range(MAX_LEN - len(line))])\n",
    "    \n",
    "with open(\"1209\\\\中央社已處理\\\\test_input_13.txt\",'r',encoding='utf-8') as text:    \n",
    "    while True:\n",
    "        line = text.readline().strip()\n",
    "        if not line:break\n",
    "        texts.append(line)\n",
    "'''       \n",
    "with open(\"1209\\\\testCorpus.txt\",'r',encoding='utf-8') as test:\n",
    "    while True:\n",
    "        line = test.readline().strip()\n",
    "        if not line:break\n",
    "        texts.append(line)\n",
    "        labels.append([0 for j in range(MAX_LEN)])\n",
    "''' \n",
    "        \n",
    "test_inputs, test_masks = preprocessing_for_bert_At(texts)\n",
    "test_labels = torch.tensor(labels)\n",
    "print(test_labels.size(), test_inputs.size())\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_labels, test_masks)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "#cor_count, df, y_real_s, y_pred_s = get_test_result(test_dataloader)\n",
    "y_real_s, y_pred_s = get_test_result(test_dataloader)\n",
    "show_confusion(y_real_s, y_pred_s)\n",
    "#df.to_csv('test/Bert20WLSTMSIGHAN2014.csv'.format(epochs,mode))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([778]) torch.Size([778, 110])\n",
      "--------------Detection level--------------\n",
      "accuracy: 0.5154241645244216\n",
      "recall: 0.9333333333333333\n",
      "precision: 0.509090909090909\n",
      "f1-score: 0.6588235294117647\n",
      "FA-Rate: 0.904639175257732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 64\n",
    "labels, texts = [], []\n",
    "with open(\"1209\\\\中央社已處理\\\\test_answer_14.txt\",'r',encoding='utf-8') as label:\n",
    "    while True:\n",
    "        line = label.readline().strip()\n",
    "        if not line:break\n",
    "        labels.append(1 if '1' in line else 0)\n",
    "        #labels.append([int(i) for i in line]+[0 for j in range(MAX_LEN - len(line))])\n",
    "    \n",
    "with open(\"1209\\\\中央社已處理\\\\test_input_14.txt\",'r',encoding='utf-8') as text:    \n",
    "    while True:\n",
    "        line = text.readline().strip()\n",
    "        if not line:break\n",
    "        texts.append(line)\n",
    "'''       \n",
    "with open(\"1209\\\\testCorpus.txt\",'r',encoding='utf-8') as test:\n",
    "    while True:\n",
    "        line = test.readline().strip()\n",
    "        if not line:break\n",
    "        texts.append(line)\n",
    "        labels.append([0 for j in range(MAX_LEN)])\n",
    "''' \n",
    "        \n",
    "test_inputs, test_masks = preprocessing_for_bert_At(texts)\n",
    "test_labels = torch.tensor(labels)\n",
    "print(test_labels.size(), test_inputs.size())\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_labels, test_masks)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "#cor_count, df, y_real_s, y_pred_s = get_test_result(test_dataloader)\n",
    "y_real_s, y_pred_s = get_test_result(test_dataloader)\n",
    "show_confusion(y_real_s, y_pred_s)\n",
    "#df.to_csv('test/Bert20WLSTMSIGHAN2014.csv'.format(epochs,mode))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1072]) torch.Size([1072, 110])\n",
      "--------------Detection level--------------\n",
      "accuracy: 0.5242537313432836\n",
      "recall: 0.8689138576779026\n",
      "precision: 0.5132743362831859\n",
      "f1-score: 0.6453407510431155\n",
      "FA-Rate: 0.8178438661710037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 64\n",
    "labels, texts = [], []\n",
    "with open(\"1209\\\\中央社已處理\\\\test_answer_15.txt\",'r',encoding='utf-8') as label:\n",
    "    while True:\n",
    "        line = label.readline().strip()\n",
    "        if not line:break\n",
    "        labels.append(1 if '1' in line else 0)\n",
    "        #labels.append([int(i) for i in line]+[0 for j in range(MAX_LEN - len(line))])\n",
    "    \n",
    "with open(\"1209\\\\中央社已處理\\\\test_input_15.txt\",'r',encoding='utf-8') as text:    \n",
    "    while True:\n",
    "        line = text.readline().strip()\n",
    "        if not line:break\n",
    "        texts.append(line)\n",
    "'''       \n",
    "with open(\"1209\\\\testCorpus.txt\",'r',encoding='utf-8') as test:\n",
    "    while True:\n",
    "        line = test.readline().strip()\n",
    "        if not line:break\n",
    "        texts.append(line)\n",
    "        labels.append([0 for j in range(MAX_LEN)])\n",
    "''' \n",
    "        \n",
    "test_inputs, test_masks = preprocessing_for_bert_At(texts)\n",
    "test_labels = torch.tensor(labels)\n",
    "print(test_labels.size(), test_inputs.size())\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_labels, test_masks)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "#cor_count, df, y_real_s, y_pred_s = get_test_result(test_dataloader)\n",
    "y_real_s, y_pred_s = get_test_result(test_dataloader)\n",
    "show_confusion(y_real_s, y_pred_s)\n",
    "#df.to_csv('test/Bert20WLSTMSIGHAN2014.csv'.format(epochs,mode))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_bert",
   "language": "python",
   "name": "pytorch_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
